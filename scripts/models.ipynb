{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../csv/data.csv\", header=None)\n",
    "df.columns = ('category', 'text', 'postid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>postid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general labor</td>\n",
       "      <td>FERRARA CANDY *** PACKAGING ASSISTANTS *** Dek...</td>\n",
       "      <td>7405032484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer service</td>\n",
       "      <td>Office Customer Service Part - Time 24 hrs/wk ...</td>\n",
       "      <td>7405099747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resumes / job wanted</td>\n",
       "      <td>quality tech control (west burbs) Manufacturin...</td>\n",
       "      <td>7396174532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resumes / job wanted</td>\n",
       "      <td>Driver Job Wanted (Chicago) CDL-Class-B Lookin...</td>\n",
       "      <td>7400075704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transportation</td>\n",
       "      <td>$400/DAY Class A LOCAL/REGIONAL CDL Driver (Le...</td>\n",
       "      <td>7406024714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category                                               text  \\\n",
       "0         general labor  FERRARA CANDY *** PACKAGING ASSISTANTS *** Dek...   \n",
       "1      customer service  Office Customer Service Part - Time 24 hrs/wk ...   \n",
       "2  resumes / job wanted  quality tech control (west burbs) Manufacturin...   \n",
       "3  resumes / job wanted  Driver Job Wanted (Chicago) CDL-Class-B Lookin...   \n",
       "4        transportation  $400/DAY Class A LOCAL/REGIONAL CDL Driver (Le...   \n",
       "\n",
       "       postid  \n",
       "0  7405032484  \n",
       "1  7405099747  \n",
       "2  7396174532  \n",
       "3  7400075704  \n",
       "4  7406024714  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "seen = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row.category == 'resumes / job wanted':\n",
    "        df.at[idx, 'category'] = 0\n",
    "    else:\n",
    "        if row.category in seen:\n",
    "            df.at[idx, 'category'] = seen[row.category]\n",
    "        else:\n",
    "            df.at[idx, 'category'] = id\n",
    "            seen[row.category] = id\n",
    "            id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# import pandas as pd\n",
    "# import csv\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = df[df[\"category\"] != 0]\n",
    "resume_list = df[df[\"category\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_collection_r = []\n",
    "processed_collection_j = []\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for post in resume_list.text:\n",
    "    #tokenize each review\n",
    "    tokens = nltk.word_tokenize(post)\n",
    "\n",
    "    #lemmatize each review and convert it to lower\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "\n",
    "    #Remove Stop Words and Punctuations\n",
    "    tokens = [token for token in tokens if not token in stopwords.words('english') if token.isalpha()]\n",
    "\n",
    "    joins = \" \".join(tokens)\n",
    "    processed_collection_r.append(joins)\n",
    "\n",
    "for post in job_list.text:\n",
    "    #tokenize each review\n",
    "    tokens = nltk.word_tokenize(post)\n",
    "\n",
    "    #lemmatize each review and convert it to lower\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "\n",
    "    #Remove Stop Words and Punctuations\n",
    "    tokens = [token for token in tokens if not token in stopwords.words('english') if token.isalpha()]\n",
    "\n",
    "    joins = \" \".join(tokens)\n",
    "    processed_collection_j.append(joins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_collection_j\n",
    "y = list(job_list.category)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n",
    "vectorizer.fit(x_train)\n",
    "x_train_m = vectorizer.transform(x_train)\n",
    "x_test_m = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(x_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.86%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Accuracy: {}%\".format(round(acc*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(x_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 78.93%\n"
     ]
    }
   ],
   "source": [
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy: {}%\".format(round(acc_svm*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 70.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=75, bootstrap=True, random_state=123)\n",
    "\n",
    "rf.fit(x_train_m, y_train)\n",
    "y_pred_rf = rf.predict(x_test_m)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"RF Accuracy: {}%\".format(round(acc_rf*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy: 66.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(20,20,15,10), random_state=123)\n",
    "nn.fit(x_train_m, y_train)\n",
    "y_pred_nn = nn.predict(x_test_m)\n",
    "acc_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(\"NN Accuracy: {}%\".format(round(acc_nn*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vec = vectorizer.transform(processed_collection_r)\n",
    "y_resume = svm.predict(resume_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(resume_list.text, y_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {v: k for k, v in seen.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "resume_list['pred_category'] = y_resume\n",
    "resume_list.pred_category = resume_list.pred_category.astype('object')\n",
    "for idx, row in resume_list.iterrows():\n",
    "    resume_list.at[idx, 'pred_category'] = categories[row.pred_category]\n",
    "\n",
    "resume_list.to_csv(\"predicted_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cosine_similarity' from 'sklearn.metrics' (/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-2348dc54dc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_collection_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(vectorizer5.vocabulary_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cosine_similarity' from 'sklearn.metrics' (/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cosine_similarity\n",
    "vectorizer5 = TfidfVectorizer()\n",
    "vectorizer5.fit(processed_collection_j)\n",
    "# print(vectorizer5.vocabulary_)\n",
    "first_job = x_train_m[0]\n",
    "first_job_y = y_train[0]\n",
    "possible_matches = \n",
    "\n",
    "cosine_similarity([v,)\n",
    "jaccard_score(v[0,:],v[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
